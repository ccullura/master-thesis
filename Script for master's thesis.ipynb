{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f00be940",
   "metadata": {},
   "source": [
    "# Script for master's thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b5e6bb",
   "metadata": {},
   "source": [
    "This script contains the programming of all the models included in the thesis \"....\"\n",
    "\n",
    "The script consist of the following: \n",
    "- Loading all the packages\n",
    "- Importing data\n",
    "- Defining ROC plot\n",
    "- Logistsic regression \n",
    "    - Standard logistic regression\n",
    "    - Ridge regression\n",
    "    - Lasso regression\n",
    "- Random forest\n",
    "    - Variable importance\n",
    "- Neural network\n",
    "    - Neural network model 1\n",
    "    - Neural network model 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b5f346",
   "metadata": {},
   "source": [
    "## Loading all the packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "seed_number = 1000\n",
    "print_flag = 1\n",
    "plot_flag = 1\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplot\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef7968",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f6ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "df=pd.read_excel(r'C:\\Users\\cullu\\OneDrive - CBS - Copenhagen Business School\\Speciale\\Output_final.xlsx')\n",
    "print(df)\n",
    "\n",
    "# Removing the columns not needed from the dataset\n",
    "useless = [\"recordID\",\"start_date\", \"end_date\", \"postal_code\",\"premium\",\"value\",\"brand\", \"age_group\", \"seniority_group\", \"hp_group\", \"fuel_group\"]\n",
    "DF_without_cats = df.drop(useless, axis=1)\n",
    "\n",
    "# Adding dummies for 'age', 'seniority', 'hp', and 'fuel'\n",
    "dummy_df=pd.get_dummies(DF_without_cats,columns=[\"age\",\"seniority\",\"hp\", \"fuel\"])\n",
    "#print(dummy_df)\n",
    "\n",
    "\n",
    "# Splitting dataset into two sets, X for the predictors and y for the response variable                                \n",
    "X = dummy_df.drop([\"status\"], axis = 1)\n",
    "y = dummy_df[\"status\"]\n",
    "\n",
    "# Splitting X and y into training dataset and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d36f90c",
   "metadata": {},
   "source": [
    "## Defining ROC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ea844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(values, colors, h=10, w=7, lab=None, EKSTRA_TEXT = \"\"):\n",
    "    sns.set()\n",
    "    fig, ax = plt.subplots(figsize=(h, w))\n",
    "    \n",
    "    colors = colors\n",
    "    i=0\n",
    "    for val in values:\n",
    "        ax.plot(val[1], val[0], label = '{} - AUC = {}'.format(lab[i], val[2]), color=colors[i])\n",
    "        i += 1\n",
    "        \n",
    "    ax.plot(np.linspace(0, 1, 30), np.linspace(0, 1, 30), label='baseline', linestyle='--', color='orange')\n",
    "    plt.title('Receiver Operating Characteristic' + EKSTRA_TEXT, fontsize=18)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.legend(loc = 'lower right', fontsize=12)\n",
    "    \n",
    "    return values, colors, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e0c73d",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0a920",
   "metadata": {},
   "source": [
    "For logistsic regression we have computed three models: \n",
    "1. Standard logistic regression\n",
    "2. Ridge regression\n",
    "3. Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36cd199",
   "metadata": {},
   "source": [
    "### Standard logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2508737",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PLAIN #####\n",
    "\n",
    "# Use the best regularization strength parameter\n",
    "# optima parameter indsat\n",
    "PLR_Model_1 = LogisticRegression()\n",
    "####################################################################################################\n",
    "                                        # grid search\n",
    "# ####################################################################################################\n",
    "\n",
    "parameters = {\n",
    "   'solver': ['newton-cg', 'lbfgs', 'sag' and 'saga'],\n",
    "     'penalty' : ['none']\n",
    "            }\n",
    "PLR_model_Grid_1 = GridSearchCV(    PLR_Model_1, \n",
    "                                         parameters, \n",
    "                                         cv=5, \n",
    "                                         scoring = \"roc_auc\", \n",
    "                                         # verbose=10, \n",
    "                                         n_jobs = -1\n",
    "                                         )\n",
    "PLR_model_Grid_1.fit(X_train, y_train)\n",
    "print(sorted(PLR_model_Grid_1.cv_results_.keys()))\n",
    "\n",
    "PLR_Model_1 = PLR_model_Grid_1\n",
    "# ####################################################################################################\n",
    "# ####################################################################################################\n",
    "\n",
    "# Training the Random Forest model\n",
    "PLR_Model_1.fit(X_train, y_train)\n",
    "# print(datetime.now() - t12)\n",
    "\n",
    "print(PLR_Model_1.best_estimator_)\n",
    "print(\"Tuned Hyperparameters :\", PLR_Model_1.best_params_)\n",
    "\n",
    "# Model accuracy\n",
    "if print_flag == 1: print(\"Accuracy: \",PLR_Model_1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6224f3a",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RIDGE #####\n",
    "\n",
    "# Use the best regularization strength parameter\n",
    "# optima parameter indsat\n",
    "PLR_Model_Ridge = LogisticRegression()\n",
    "#penalty = 'l2', \n",
    "                           # random_state = seed_number,\n",
    "                            #solver = 'newton-cg', \n",
    "                            #C=0.0017, \n",
    "                            ##class_weight=\"balanced\"\n",
    "####################################################################################################\n",
    "                                        # grid search\n",
    "# ####################################################################################################\n",
    "\n",
    "parameters = {\n",
    "    'C':np.logspace(-3,3,50),\n",
    "   'solver': ['newton-cg', 'lbfgs', 'sag' and 'saga'],\n",
    "     'penalty' : ['l2']\n",
    "            }\n",
    "PLR_model_Ridge_Grid = GridSearchCV(    PLR_Model_Ridge, \n",
    "                                         parameters, \n",
    "                                         cv=5, \n",
    "                                         scoring = \"roc_auc\", \n",
    "                                         # verbose=10, \n",
    "                                         n_jobs = -1\n",
    "                                         )\n",
    "PLR_model_Ridge_Grid.fit(X_train, y_train)\n",
    "print(sorted(PLR_model_Ridge_Grid.cv_results_.keys()))\n",
    "\n",
    "PLR_Model_Ridge = PLR_model_Ridge_Grid\n",
    "# ####################################################################################################\n",
    "# ####################################################################################################\n",
    "\n",
    "# Training the Random Forest model\n",
    "PLR_Model_Ridge.fit(X_train, y_train)\n",
    "# print(datetime.now() - t12)\n",
    "\n",
    "print(PLR_Model_Ridge.best_estimator_)\n",
    "print(\"Tuned Hyperparameters :\", PLR_Model_Ridge.best_params_)\n",
    "\n",
    "# Model accuracy\n",
    "if print_flag == 1: print(\"Accuracy: \",PLR_Model_Ridge.score(X_test, y_test))\n",
    "\n",
    "# Model prediction\n",
    "PLR_Model_Ridge_preds = PLR_Model_Ridge.predict(X_test)\n",
    "# Probability predicting for ROC plot\n",
    "PLR_Model_Ridge_probs = PLR_Model_Ridge.predict_proba(X_test)[:,1]\n",
    "# Model prediction\n",
    "PLR_Model_Ridge_preds = np.where(PLR_Model_Ridge_probs > 0.5, 1, 0)\n",
    "\n",
    "# Used for confusion matrix\n",
    "y_prediction = dict()\n",
    "y_prediction['status'] = y_test.copy()\n",
    "y_prediction[\"Preds\"] = PLR_Model_Ridge_preds\n",
    "\n",
    "# Make confusion matrix\n",
    "confusion_matrixs = pd.crosstab(y_prediction['status'], y_prediction[\"Preds\"], rownames=['Actual'], colnames=['Predicted'])\n",
    "if print_flag == 1: print(\"Confusion Matrix: \\n\",confusion_matrixs)\n",
    "\n",
    "# Classification report with f1, recall, precision and accuract of the model\n",
    "Class_DF = classification_report(y_test, PLR_Model_Ridge_preds,output_dict = True)\n",
    "if print_flag == 1: print(\"Classification parameters: \\n\",pd.DataFrame(Class_DF))\n",
    "\n",
    "# # Probability predicting for ROC plot\n",
    "# PLR_Model_Ridge_probs = PLR_Model_Ridge.predict_proba(X_test)[:,1]\n",
    "\n",
    "# ROC plot\n",
    "## calculate fpr and tpr to use in ROC plot\n",
    "if plot_flag == 1:\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, PLR_Model_Ridge_probs)\n",
    "    roc_auc = round(metrics.auc(fpr, tpr), 10)\n",
    "    rates_list = [[tpr, fpr, roc_auc]]\n",
    "    ## Creates the ROC plot\n",
    "    roc_plot(values = rates_list, colors=['blue'], lab = [\"Ridge Logistic Regression\"])\n",
    "os.system('say \"Ridge log is done.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e983bf",
   "metadata": {},
   "source": [
    "### Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b733f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### LASSO ######\n",
    "\n",
    "# Use the best regularization strength parameter\n",
    "# optima parameter indsat\n",
    "PLR_Model_Lasso = LogisticRegression(penalty = 'l1', \n",
    "                            random_state = seed_number,\n",
    "                            solver = 'liblinear', \n",
    "                            C=0.089, \n",
    "                            # class_weight=\"balanced\"\n",
    "                            )\n",
    "'liblinear' and 'saga' \n",
    "# ####################################################################################################\n",
    "#                                         # grid search\n",
    "# ####################################################################################################\n",
    "\n",
    "parameters = {\n",
    "    'C':np.arange(0,10,0.1),\n",
    "   'solver': ['newton-cg', 'lbfgs', 'liblinear','sag' and 'saga'],\n",
    "     'penalty' : ['l1']\n",
    "            }\n",
    "PLR_model_Lasso_Grid = GridSearchCV(          PLR_Model_Lasso, \n",
    "                                         parameters, \n",
    "                                         cv=5, \n",
    "                                         scoring = \"roc_auc\", \n",
    "                                         # verbose=10, \n",
    "                                         n_jobs = -1\n",
    "                                         )\n",
    "PLR_model_Lasso_Grid.fit(X_train, y_train)\n",
    "#print(sorted(PLR_model_Grid.cv_results_.keys()))\n",
    "\n",
    "PLR_Model_Lasso = PLR_model_Lasso_Grid\n",
    "# ####################################################################################################\n",
    "# ###################################################################################################\n",
    "\n",
    "# Training the Random Forest model\n",
    "PLR_Model_Lasso.fit(X_train, y_train)\n",
    "# print(datetime.now() - t12)\n",
    "\n",
    "print(PLR_Model_Lasso.best_estimator_)\n",
    "print(\"Tuned Hyperparameters :\", PLR_Model_Lasso.best_params_)\n",
    "\n",
    "# Model accuracy\n",
    "if print_flag == 1: print(\"Accuracy: \",PLR_Model_Lasso.score(X_test, y_test))\n",
    "\n",
    "    # Model prediction\n",
    "PLR_Model_Lasso_preds = PLR_Model_Lasso.predict(X_test)\n",
    "# Probability predicting for ROC plot\n",
    "PLR_Model_Lasso_probs = PLR_Model_Lasso.predict_proba(X_test)[:,1]\n",
    "# Model prediction\n",
    "PLR_Model_Lasso_preds = np.where(PLR_Model_Lasso_probs > 0.35, 1, 0)\n",
    "\n",
    "#PLR_Model_Lasso.coef_    # dense np.array\n",
    "\n",
    "\n",
    "\n",
    "# Used for confusion matrix\n",
    "y_prediction = dict()\n",
    "y_prediction['dropouts'] = y_test.copy()\n",
    "y_prediction[\"Preds\"] = PLR_Model_Lasso_preds\n",
    "\n",
    "# Make confusion matrix\n",
    "confusion_matrixs = pd.crosstab(y_prediction['dropouts'], y_prediction[\"Preds\"], rownames=['Actual'], colnames=['Predicted'])\n",
    "if print_flag == 1: print(\"Confusion Matrix: \\n\",confusion_matrixs)\n",
    "\n",
    "# Classification report with f1, recall, precision and accuract of the model\n",
    "Class_DF = classification_report(y_test, PLR_Model_Lasso_preds,output_dict = True)\n",
    "if print_flag == 1: print(\"Classification parameters: \\n\",pd.DataFrame(Class_DF))\n",
    "\n",
    "# # Probability predicting for ROC plot\n",
    "PLR_Model_Lasso_probs = PLR_Model_Lasso.predict_proba(X_test)[:,1]\n",
    "#print(datetime.now() - t1)\n",
    "\n",
    "# ROC plot\n",
    "## calculate fpr and tpr to use in ROC plot\n",
    "if plot_flag == 1:\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, PLR_Model_Lasso_probs)\n",
    "    roc_auc = round(metrics.auc(fpr, tpr), 10)\n",
    "    rates_list = [[tpr, fpr, roc_auc]]\n",
    "    ## Creates the ROC plot\n",
    "    roc_plot(values = rates_list, colors=['blue'], lab = [\"Lasso Logistic Regression\"])\n",
    "os.system('say \"Lasso log is done.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848259a8",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e446be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t1 = datetime.now()\n",
    "#print(t1)\n",
    "# function specifications\n",
    "plot_flag = 1\n",
    "print_flag = 1\n",
    "#DF = Transposed_DF\n",
    "\n",
    "## Random Forest model specified\n",
    "# Her kan man regulere om det er balanced eller ej\n",
    "# Har intastet de bedste parametre\n",
    "# RF_Model = RandomForestClassifier(  \n",
    "#                                     # n_estimatorsint = \n",
    "#                                     max_depth = 80, \n",
    "#                                     random_state = seed_number,\n",
    "#                                     bootstrap = True,\n",
    "#                                     criterion = 'entropy', \n",
    "#                                     max_features = 54,\n",
    "#                                     # max_features = \"sqrt\",\n",
    "#                                     n_estimators = 300,\n",
    "#                                 )\n",
    "# for balanceret                                \n",
    "RF_Model = RandomForestClassifier(  \n",
    "                                    # n_estimatorsint = \n",
    "                                    #max_depth = 33, \n",
    "                                    random_state = seed_number,\n",
    "                                    bootstrap = True,\n",
    "                                    oob_score = True,\n",
    "                                    #criterion = 'entropy', \n",
    "                                    #max_features = 80,\n",
    "                                    # max_features = \"sqrt\",\n",
    "                                    #n_estimators = 600,\n",
    "                                    #class_weight = \"balanced\"\n",
    "                                )\n",
    "# Splitting dataset into X,y sets                                \n",
    "#X = DF.drop([\"dropouts\"], axis = 1)\n",
    "#y = DF[\"dropouts\"]\n",
    "\n",
    "# Split data into test and train\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed_number)\n",
    "\n",
    "# ####################################################################################################\n",
    "#                                         # grid search\n",
    "# ####################################################################################################\n",
    "#t12 = datetime.now()\n",
    "# print(t12)\n",
    "#n_variables = len(Transposed_DF.columns)\n",
    "parameters = {\n",
    "     'criterion': ['entropy'],\n",
    "     'max_depth':[10],\n",
    "     #'max_features': ['sqrt'],\n",
    "     'max_features': [8],\n",
    "     'n_estimators': [1200],\n",
    "     #'min_samples_split'\n",
    "     #'min_samples_leaf'\n",
    "     # max_leaf_nodes\n",
    "     # min_impurity_decrease\n",
    "     # max_samples\n",
    "             }\n",
    "RF_Model_Grid = GridSearchCV(    RF_Model, \n",
    "                                         parameters, \n",
    "                                         cv=5, scoring = \"roc_auc\", \n",
    "                                         verbose=10, \n",
    "                                        # n_jobs = -1\n",
    "                                         )\n",
    "RF_Model_Grid.fit(X_train, y_train)\n",
    "print(sorted(RF_Model_Grid.cv_results_.keys()))\n",
    "#print(datetime.now() - t12)\n",
    "\n",
    "RF_Model = RF_Model_Grid\n",
    "os.system('say \"Gridsearch is done.\"')\n",
    "# ####################################################################################################\n",
    "# ####################################################################################################\n",
    "\n",
    "# Training the Random Forest model\n",
    "#RF_Model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# print(RF_Model.best_estimator_)\n",
    "\n",
    "# Model accuracy\n",
    "if print_flag == 1: print(\"Accuracy: \",RF_Model.score(X_test, y_test))\n",
    "\n",
    "# Model prediction\n",
    "RF_Model_preds = RF_Model.predict(X_test)\n",
    "# Probability predicting for ROC plot\n",
    "RF_Model_probs = RF_Model.predict_proba(X_test)[:,1]\n",
    "# Model prediction\n",
    "RF_Model_preds = np.where(RF_Model_probs > 0.5, 1, 0)\n",
    "# Used for confusion matrix\n",
    "y_prediction = dict()\n",
    "y_prediction['dropouts'] = y_test.copy()\n",
    "y_prediction[\"Preds\"] = RF_Model_preds\n",
    "\n",
    "# Make confusion matrix\n",
    "confusion_matrixs = pd.crosstab(y_prediction['dropouts'], y_prediction[\"Preds\"], rownames=['Actual'], colnames=['Predicted'])\n",
    "if print_flag == 1: print(\"Confusion Matrix:\\n\",confusion_matrixs)\n",
    "\n",
    "# Classification report with f1, recall, precision and accuract of the model\n",
    "Class_DF = classification_report(y_test, RF_Model_preds,output_dict = True)\n",
    "if print_flag == 1: print(\"Classification parameters:\\n\",pd.DataFrame(Class_DF))\n",
    "\n",
    "# Probability predicting for ROC plot\n",
    "RF_Model_probs = RF_Model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# ROC plot\n",
    "## calculate fpr and tpr to use in ROC plot\n",
    "if plot_flag == 1:\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, RF_Model_probs)\n",
    "    roc_auc = round(metrics.auc(fpr, tpr), 4)\n",
    "    rates_list = [[tpr, fpr, roc_auc]]\n",
    "    ## Creates the ROC plot\n",
    "    roc_plot(values = rates_list, colors=['blue'], lab = [\"Random Forrest\"])\n",
    "os.system('say \"Random Fores is done.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c62fd2",
   "metadata": {},
   "source": [
    "### Variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e01a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(  max_depth = 10, \n",
    "                                    random_state = seed_number,\n",
    "                                    bootstrap = True,\n",
    "                                    criterion = 'entropy', \n",
    "                                    max_features = 8,\n",
    "                                    # max_features = \"sqrt\",\n",
    "                                    n_estimators = 1200,\n",
    "                                    oob_score = True\n",
    "                                    #class_weight = \"balanced\"\n",
    "                                )\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf.feature_importances_\n",
    "\n",
    "rf.oob_score_\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "importances = rf.feature_importances_\n",
    "#\n",
    "# Sort the feature importance in descending order\n",
    "#\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    " \n",
    "feat_labels = dummy_df.columns[1:]\n",
    " \n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,\n",
    "                            feat_labels[sorted_indices[f]],\n",
    "                            importances[sorted_indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3883b2",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d03606c",
   "metadata": {},
   "source": [
    "### Neural network model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be279f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
